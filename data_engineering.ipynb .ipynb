{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1\n",
    "\n",
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the provided CSV data into DataFrames\n",
    "stations=\"hawaii_stations.csv\"\n",
    "weather=\"hawaii_measurements.csv\"\n",
    "stations_data=pd.read_csv(stations,encoding=\"iso-8859-1\")\n",
    "weather_data=pd.read_csv(weather,encoding=\"iso-8859-1\")\n",
    "stations_df=pd.DataFrame(stations_data)\n",
    "weather_df=pd.DataFrame(weather_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data to see missing data points.  looks like NaN's in 'prcp' column.\n",
    "weather_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at the data\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the numbers\n",
    "weather_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data to see missing data points.\n",
    "stations_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full look at the data, appears to be in good shape.\n",
    "stations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pivot table to look at the average rain and temp numbers per station\n",
    "# will help be evaluate the impact of the NaN's.\n",
    "\n",
    "nan_eval=weather_df\n",
    "nan_eval=pd.pivot_table(nan_eval,index=['station'], values=['prcp','tobs'])\n",
    "nan_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table to look at the NaN impact of rain volumn on each station.  Since it ranges from 0\n",
    "# to just over 50% I do not want to drop rows without rain values since I will also be losing\n",
    "# the temperature (significant impact). From prior pivot table, it appears that if I replace the\n",
    "# NaN's with 0's I will have less data impact than dropping all of the rows with NaN's.\n",
    "\n",
    "test=weather_df\n",
    "test['NaN Count']=test['prcp'].isnull()\n",
    "test['Count']=1\n",
    "test=pd.pivot_table(test,index=[\"station\"], values=['Count','NaN Count'],aggfunc=np.sum)\n",
    "test['percentage']=test['NaN Count']/test['Count']*100\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the two files and make sure the weather stations match up.\n",
    "\n",
    "stat_test1=stations_df['station']\n",
    "stat_test2=weather_df['station'].unique()\n",
    "clean= (stat_test1==stat_test2)\n",
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last check is to review the rain and temp data for reasonability \n",
    "\n",
    "minrain = weather_df['prcp'].min()\n",
    "maxrain = weather_df['prcp'].max()\n",
    "maxtemp = weather_df['tobs'].max()\n",
    "mintemp = weather_df['tobs'].min()\n",
    "print('maxrain : ', maxrain, ' | minrain : ',minrain, ' | maxtemp : ', maxtemp, ' | mintemp : ',mintemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN's with number 0 and save the clean data.  The rain numbers are small (first pivottable)\n",
    "# and I don't want to trash the temp data, so rather than dropping all the good temp data I'm putting\n",
    "#  zero in the NaN place since it looks like it won't impact the data as much as the loss of temp.\n",
    "\n",
    "clean_stations_df=pd.DataFrame(stations_data)\n",
    "clean_weather_df=pd.DataFrame(weather_data)\n",
    "clean_weather_df.drop('NaN Count', axis=1, inplace=True)\n",
    "clean_weather_df.drop('Count', axis=1, inplace=True)\n",
    "clean_weather_df = clean_weather_df.fillna(0)\n",
    "clean_weather_df.to_csv(\"clean_hawaii_measurements.csv\", index = False)\n",
    "clean_stations_df.to_csv(\"clean_hawaii_stations.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2\n",
    "\n",
    "# Import SQLAlchemy and other dependencies \n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Numeric, Text, Float\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an engine to a database file called `hawaii.sqlite`\n",
    "engine = create_engine(\"sqlite:///hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the engine called `conn`\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `declarative_base` from SQLAlchemy to model the tables as an ORM class\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Measurement Class\n",
    "# ----------------------------------\n",
    "class Measurements(Base):\n",
    "    __tablename__ = 'measurements'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    station = Column(String(15))\n",
    "    date = Column(String(15))\n",
    "    prcp = Column(Float)\n",
    "    tobs = Column(Integer)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"id={self.id}, name={self.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Station class\n",
    "# ---------------------------------------\n",
    "class Station(Base):\n",
    "    __tablename__ = 'station'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    station = Column(String(15))\n",
    "    name = Column(String(45))\n",
    "    latitude = Column(Float)\n",
    "    longitude = Column(Float)\n",
    "    elevation = Column(Float)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"id={self.id}, name={self.name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using `create_all`, creates the tables in the database\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned csv file into a pandas dataframe\n",
    "df_of_measurements = pd.read_csv('clean_hawaii_measurements.csv')\n",
    "df_of_stations = pd.read_csv('clean_hawaii_stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Orient='records' to create a list of data to write\n",
    "weather_data = df_of_measurements.to_dict(orient='records')\n",
    "station_data = df_of_stations.to_dict(orient='records')\n",
    "weather_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use MetaData from SQLAlchemy to reflect the tables\n",
    "\n",
    "metadata = MetaData(bind=engine)\n",
    "metadata.reflect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reference to the `demographics` table as a variable called `table`\n",
    "\n",
    "weather_table = sqlalchemy.Table('measurements', metadata, autoload=True)\n",
    "station_table = sqlalchemy.Table('station', metadata, autoload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `table.delete()` to remove any existing data.\n",
    "# Note that this is a convenience function so that you can re-run the example code multiple times.\n",
    "# You would not likely do this step in production.\n",
    "\n",
    "conn.execute(weather_table.delete())\n",
    "conn.execute(station_table.delete())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `table.insert()` to insert the data into the table\n",
    "\n",
    "conn.execute(weather_table.insert(), weather_data)\n",
    "conn.execute(station_table.insert(), station_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the insert works by fetching the first 5 rows. \n",
    "conn.execute(\"select * from measurements limit 5\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"select * from station\").fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3\n",
    "\n",
    "# Import SQLAlchemy and other dependencies \n",
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, inspect, func\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "style.use('seaborn')\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import Column, Integer, String, Float, Text, ForeignKey\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine using the `hawaii.sqlite` database file created in database_engineering steps\n",
    "\n",
    "engine = create_engine(\"sqlite:///hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a Base using `automap_base()`\n",
    "\n",
    "Base = automap_base()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Base class to reflect the database tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all of the classes mapped to the Base\n",
    "\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the inspector and connect it to the engine\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Collect the names of tables within the database\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `engine.execute` to select and display the first 10 rows from the table\n",
    "\n",
    "engine.execute('SELECT * FROM measurements LIMIT 10').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect Database into ORM class\n",
    "Station = Base.classes.station\n",
    "Measurements = Base.classes.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session to query the database\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabs the last date entry in the data table\n",
    "last_date = session.query(Measurements.date).order_by(Measurements.date.desc()).first()\n",
    "print(last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the last 12 months of data, last date - 365\n",
    "last_year = dt.date(2017, 8, 23) - dt.timedelta(days=365)\n",
    "print(last_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to pull the last year of precipitation data\n",
    "rain = session.query(Measurements.date, Measurements.prcp).\\\n",
    "    filter(Measurements.date > last_year).\\\n",
    "    order_by(Measurements.date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the query into a dataframe\n",
    "\n",
    "rain_df = pd.DataFrame(rain)\n",
    "rain_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index to the date\n",
    "\n",
    "rain_df.set_index('date').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dataframe\n",
    "rain_df.plot('date', 'prcp')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Rain in Inches\")\n",
    "plt.title(\"Precipitation Analysis (8/24/16 to 8/23/17)\")\n",
    "plt.legend([\"Precipitation\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to print the summary statistics for the precipitation data.\n",
    "rain_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of stations in the Measurement table\n",
    "locations = session.query(Measurements).group_by(Measurements.station).count()\n",
    "print(\"There are {} stations.\".format(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the station with the most temperature observations, then list them all in descending order\n",
    "busy_station = session.query(Measurements.station, func.count(Measurements.tobs)).group_by(Measurements.station).\\\n",
    "               order_by(func.count(Measurements.tobs).desc()).all()\n",
    "\n",
    "busiest = busy_station[0][0]    \n",
    "print(\"The busiest Station was\",busiest,\"with\",busy_station[0][1],\"weather observations.\")\n",
    "print()\n",
    "print(\"Here are all of the Stations (in descending order) with their number of observations:\")\n",
    "for station, count in busy_station:\n",
    "    print(\"Station\",station,\"had\",count, \"weather observations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to pull the last year of precipitation data for the busiest station\n",
    "temperature = session.query(Measurements.station, Measurements.date, Measurements.tobs).\\\n",
    "    filter(Measurements.station == busiest).\\\n",
    "    filter(Measurements.date > last_year).\\\n",
    "    order_by(Measurements.date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the temperature data in a histogram with 12 bins\n",
    "temp_df=pd.DataFrame(temperature)\n",
    "plt.hist(temp_df['tobs'],12)\n",
    "plt.xlabel(\"Recorded Temperature\")\n",
    "plt.ylabel(\"Number of Recorded Observations\")\n",
    "plt.title(\"Station Analysis (8/24/16 to 8/23/17) for Station \" + busiest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function called `calc_temps` that will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurements.tobs), func.avg(Measurements.tobs), func.max(Measurements.tobs)).\\\n",
    "        filter(Measurements.date >= start_date).filter(Measurements.date <= end_date).all()\n",
    "temp_range = (calc_temps('2012-02-28', '2012-03-05'))\n",
    "print(temp_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the min/max/avg from last year that matches my trip date\n",
    "trip_arrive = dt.date(2018, 4, 1)\n",
    "trip_leave = dt.date(2018, 4, 15)\n",
    "last_year = dt.timedelta(days=365)\n",
    "temp_avg_lst_year = (calc_temps((trip_arrive-last_year), (trip_leave-last_year)))\n",
    "print(temp_avg_lst_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data as a boxplot\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(len(temp_avg_lst_year))\n",
    "ax.boxplot(temp_avg_lst_year, patch_artist=True)\n",
    "ax.set_title('Trip Average Temperature From Prior Year')\n",
    "ax.set_ylabel(\"Temperature\")\n",
    "ax.set_xlabel(\"Trip\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the calculated min/max/avg from last year for the trip dates as a bar chart\n",
    "\n",
    "p2p = temp_avg_lst_year[0][2]-temp_avg_lst_year[0][0]\n",
    "avgtemp = temp_avg_lst_year[0][1]\n",
    "min_temp = temp_avg_lst_year[0][0]\n",
    "max_temp = temp_avg_lst_year[0][2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar_chart = ax.bar(1 , avgtemp, color= 'red', yerr=p2p)\n",
    "ax.set_xlabel(\"Trip\")\n",
    "ax.set_ylabel(\"Temperature\")\n",
    "ax.set_title(\"Trip Average Temperature From Prior Year\")\n",
    "\n",
    "def autolabels(rects):\n",
    "    for rect in rects:\n",
    "        h=rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., .6*h,'%.2f' % float(h) ,ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "        \n",
    "    # label the bars \n",
    "autolabels(bar_chart)        \n",
    "plt.ylim(0, 100)\n",
    "plt.xlim(0,2)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the trip variables of arrive and leave for prior year\n",
    "lst_year_arrive = trip_arrive - last_year\n",
    "lst_year_leave = trip_leave - last_year\n",
    "print(lst_year_arrive)\n",
    "print(lst_year_leave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query to pull the rain fall from last year matching this years trip\n",
    "vacation_data = session.query(Measurements.station, Measurements.date, Measurements.prcp, Measurements.tobs).\\\n",
    "    filter(Measurements.date >= lst_year_arrive).\\\n",
    "    filter(Measurements.date <= lst_year_leave).\\\n",
    "    order_by(Measurements.station).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the query results into a dataframe and pivot on station\n",
    "vacation_data_df=pd.DataFrame(vacation_data)\n",
    "\n",
    "rain_per_station = pd.pivot_table(vacation_data_df,index=['station'],values=['prcp'], aggfunc=sum)\n",
    "rain_per_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4\n",
    "\n",
    "# import dependencies \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func\n",
    "from flask import Flask, jsonify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Setup\n",
    "\n",
    "engine = create_engine(\"sqlite:///Hawaii.sqlite\")\n",
    "# reflect the database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reference to the table\n",
    "Station = Base.classes.station\n",
    "Measurements = Base.classes.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask Setup\n",
    "app = Flask(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask Routes\n",
    "\n",
    "@app.route(\"/\")\n",
    "def welcome():\n",
    "    \"\"\"List all available api routes.\"\"\"\n",
    "    return (\n",
    "        f\"Available Routes:<br/>\"\n",
    "        f\"<br/>\"\n",
    "        f\"/api/v1.0/precipitation<br/>\"\n",
    "        f\"- List of prior year rain totals from all stations<br/>\"\n",
    "        f\"<br/>\"\n",
    "        f\"/api/v1.0/stations<br/>\"\n",
    "        f\"- List of Station numbers and names<br/>\"\n",
    "        f\"<br/>\"\n",
    "        f\"/api/v1.0/tobs<br/>\"\n",
    "        f\"- List of prior year temperatures from all stations<br/>\"\n",
    "        f\"<br/>\"\n",
    "        f\"/api/v1.0/start<br/>\"\n",
    "        f\"- When given the start date (YYYY-MM-DD), calculates the MIN/AVG/MAX temperature for all dates greater than and equal to the start date<br/>\"\n",
    "        f\"<br/>\"\n",
    "        f\"/api/v1.0/start/end<br/>\"\n",
    "        f\"- When given the start and the end date (YYYY-MM-DD), calculate the MIN/AVG/MAX temperature for dates between the start and end date inclusive<br/>\"\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/v1.0/precipitation\")\n",
    "def precipitation():\n",
    "    \"\"\"Return a list of rain fall for prior year\"\"\"\n",
    "#    * Query for the dates and precipitation observations from the last year.\n",
    "#           * Convert the query results to a Dictionary using `date` as the key and `prcp` as the value.\n",
    "#           * Return the json representation of your dictionary.\n",
    "    last_date = session.query(Measurements.date).order_by(Measurements.date.desc()).first()\n",
    "    last_year = dt.date(2017, 8, 23) - dt.timedelta(days=365)\n",
    "    rain = session.query(Measurements.date, Measurements.prcp).\\\n",
    "        filter(Measurements.date > last_year).\\\n",
    "        order_by(Measurements.date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dicts with `date` and `prcp` as the keys and values\n",
    "    rain_totals = []\n",
    "    for result in rain:\n",
    "        row = {}\n",
    "        row[\"date\"] = rain[0]\n",
    "        row[\"prcp\"] = rain[1]\n",
    "        rain_totals.append(row)\n",
    "\n",
    "    return jsonify(rain_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/v1.0/stations\")\n",
    "def stations():\n",
    "    stations_query = session.query(Station.name, Station.station)\n",
    "    stations = pd.read_sql(stations_query.statement, stations_query.session.bind)\n",
    "    return jsonify(stations.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/v1.0/tobs\")\n",
    "def tobs():\n",
    "    \"\"\"Return a list of temperatures for prior year\"\"\"\n",
    "#    * Query for the dates and temperature observations from the last year.\n",
    "#           * Convert the query results to a Dictionary using `date` as the key and `tobs` as the value.\n",
    "#           * Return the json representation of your dictionary.\n",
    "    last_date = session.query(Measurements.date).order_by(Measurements.date.desc()).first()\n",
    "    last_year = dt.date(2017, 8, 23) - dt.timedelta(days=365)\n",
    "    temperature = session.query(Measurements.date, Measurements.tobs).\\\n",
    "        filter(Measurements.date > last_year).\\\n",
    "        order_by(Measurements.date).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dicts with `date` and `tobs` as the keys and values\n",
    "    temperature_totals = []\n",
    "    for result in temperature:\n",
    "        row = {}\n",
    "        row[\"date\"] = temperature[0]\n",
    "        row[\"tobs\"] = temperature[1]\n",
    "        temperature_totals.append(row)\n",
    "\n",
    "    return jsonify(temperature_totals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/v1.0/<start>\")\n",
    "def trip1(start):\n",
    "\n",
    " # go back one year from start date and go to end of data for Min/Avg/Max temp   \n",
    "    start_date= dt.datetime.strptime(start, '%Y-%m-%d')\n",
    "    last_year = dt.timedelta(days=365)\n",
    "    start = start_date-last_year\n",
    "    end =  dt.date(2017, 8, 23)\n",
    "    trip_data = session.query(func.min(Measurements.tobs), func.avg(Measurements.tobs), func.max(Measurements.tobs)).\\\n",
    "        filter(Measurements.date >= start).filter(Measurements.date <= end).all()\n",
    "    trip = list(np.ravel(trip_data))\n",
    "    return jsonify(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/api/v1.0/<start>/<end>\")\n",
    "def trip2(start,end):\n",
    "\n",
    "  # go back one year from start/end date and get Min/Avg/Max temp     \n",
    "    start_date= dt.datetime.strptime(start, '%Y-%m-%d')\n",
    "    end_date= dt.datetime.strptime(end,'%Y-%m-%d')\n",
    "    last_year = dt.timedelta(days=365)\n",
    "    start = start_date-last_year\n",
    "    end = end_date-last_year\n",
    "    trip_data = session.query(func.min(Measurements.tobs), func.avg(Measurements.tobs), func.max(Measurements.tobs)).\\\n",
    "        filter(Measurements.date >= start).filter(Measurements.date <= end).all()\n",
    "    trip = list(np.ravel(trip_data))\n",
    "    return jsonify(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
